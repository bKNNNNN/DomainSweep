# CLAUDE.md - DomainSweep

> Guide for DomainSweep - Mass domain accessibility checker (6M+ domains)

## Project Overview

**Goal:** Check the accessibility of 6 million domains as fast as possible using a funnel approach:
1. DNS/MX validation ‚Üí Filter dead domains
2. HTTP/HTTPS probing ‚Üí Check web accessibility  
3. Cloudflare bypass ‚Üí Handle protected sites

---

## Stack Technique

**YOU MUST use these tools (all open source/free):**

### DNS Resolution
| Priority | Tool | Use Case | Install |
|----------|------|----------|---------|
| ü•á Primary | `dnsx` | MX/A record checks, wildcard filtering | `go install github.com/projectdiscovery/dnsx/cmd/dnsx@latest` |
| ü•à Fallback 1 | `massdns` | Raw speed (350k/sec) | `git clone https://github.com/blechschmidt/massdns && make` |
| ü•â Fallback 2 | `zdns` | JSON output, reliable | `go install github.com/zmap/zdns@latest` |

### HTTP Probing
| Priority | Tool | Use Case | Install |
|----------|------|----------|---------|
| ü•á Primary | `httpx` | Mass HTTP probing with tech detection | `go install github.com/projectdiscovery/httpx/cmd/httpx@latest` |
| ü•à Fallback 1 | `curl_cffi` | TLS fingerprint bypass | `pip install curl_cffi` |
| ü•â Fallback 2 | `httprobe` | Lightweight alternative | `go install github.com/tomnomnom/httprobe@latest` |

### Cloudflare Bypass
| Priority | Tool | Use Case | Install |
|----------|------|----------|---------|
| ü•á Primary | `curl_cffi` | TLS/JA3 fingerprint impersonation | `pip install curl_cffi` |
| ü•à Fallback 1 | `FlareSolverr` | Headless browser solver | `docker pull flaresolverr/flaresolverr` |
| ü•â Fallback 2 | `cloudscraper` | JS challenge solver | `pip install cloudscraper` |

### Data Processing
| Tool | Use Case | Install |
|------|----------|---------|
| `jq` | JSON processing | `apt install jq` |
| `csvkit` | CSV manipulation | `pip install csvkit` |
| `GNU parallel` | Parallel execution | `apt install parallel` |

### Infrastructure
| Tool | Use Case |
|------|----------|
| Docker | Container management |
| Python 3.11+ | Scripting |
| Go 1.21+ | Tool compilation |

---

## Pre-Commit Rules

**BEFORE ANY COMMIT TO GITHUB, YOU MUST:**
1. Run `/review-changes` to review all code modifications
2. Ensure all tests pass
3. Check that no sensitive data (API keys, passwords) is included
4. Verify documentation is updated if needed

---

## Infrastructure Recommendation

**‚ö†Ô∏è BEFORE RUNNING ANY SCAN SCRIPT, ALWAYS REMIND THE USER:**

```
üîí INFRASTRUCTURE CHECK:
- ‚ùå Do NOT use a VPN (throttled bandwidth, unstable, DNS leaks)
- ‚úÖ Use a dedicated VPS (Hetzner, OVH, Scaleway ~5‚Ç¨/month)
- ‚úÖ Or use your local connection for small tests (< 10k domains)
- ‚úÖ For Cloudflare bypass: consider residential proxies if needed
```

**Why no VPN?**
- VPN providers throttle high DNS/UDP traffic
- Shared IPs are often already flagged
- Connection drops cause scan failures
- See: [massdns Mullvad issue](https://github.com/projectdiscovery/dnsx/issues/221)

**Why not your home connection for large scans?**

Your ISP will likely flag unusual activity:
| Risk | Probability | Consequence |
|------|-------------|-------------|
| DNS throttling | üî¥ High | Requests become slow (rate limited) |
| Temp port 53 block | üü† Medium | No DNS resolution for a few hours |
| Warning email | üü° Low | "Unusual activity detected" |
| Service suspension | üü¢ Very low | Only for repeat offenders |

Rule of thumb:
- < 10k domains ‚Üí Your connection is fine
- 10k-500k domains ‚Üí Spread over several hours
- 500k+ domains ‚Üí **Use a VPS** (safest option)

**TL;DR:** A VPS costs 4-5‚Ç¨/month and avoids all ISP issues. Your ISP only sees one encrypted SSH connection. No questions asked.

**Recommended setup for 6M domains:**
```bash
# Rent a cheap VPS with good bandwidth
# Example: Hetzner CX22 (2 vCPU, 4GB RAM, 40GB SSD) = ~4‚Ç¨/month

# Connect via SSH and run scripts there
ssh user@your-vps-ip
cd domain-checker
make run-all
```

---

## Code Guidelines

**IMPORTANT:** ALL code must be in English (variables, functions, comments, logs)

**YOU MUST:**
- Write modular scripts with clear separation of concerns
- Implement retry logic with exponential backoff
- Use streaming/chunked processing for large files (never load 6M lines in memory)
- Log progress and errors to separate files
- Support resume functionality for long-running tasks
- Output results in both JSON and CSV formats

**Naming Conventions:**
```
Scripts:      01_dns_check.py, 02_http_probe.py
Outputs:      results_dns_YYYYMMDD.json
Logs:         logs/dns_check_YYYYMMDD.log
Temp files:   tmp/chunk_001.txt
```

**Error Handling Pattern:**
```python
def process_domain(domain: str) -> dict:
    """Always return a dict with status, never raise exceptions"""
    try:
        # Primary tool
        result = primary_tool(domain)
    except Exception as e:
        try:
            # Fallback 1
            result = fallback_tool_1(domain)
        except Exception as e2:
            # Fallback 2 or error state
            result = {"domain": domain, "status": "error", "error": str(e2)}
    return result
```

---

## Architecture

```
input/
‚îú‚îÄ‚îÄ domains.txt              # 6M domains (one per line)
‚îî‚îÄ‚îÄ resolvers.txt            # DNS resolvers list

output/
‚îú‚îÄ‚îÄ 01_dns_results/
‚îÇ   ‚îú‚îÄ‚îÄ domains_with_mx.txt
‚îÇ   ‚îú‚îÄ‚îÄ domains_with_a.txt
‚îÇ   ‚îî‚îÄ‚îÄ dns_errors.txt
‚îú‚îÄ‚îÄ 02_http_results/
‚îÇ   ‚îú‚îÄ‚îÄ http_alive.json
‚îÇ   ‚îú‚îÄ‚îÄ cloudflare_detected.txt
‚îÇ   ‚îî‚îÄ‚îÄ http_errors.txt
‚îú‚îÄ‚îÄ 03_bypass_results/
‚îÇ   ‚îú‚îÄ‚îÄ bypass_success.json
‚îÇ   ‚îî‚îÄ‚îÄ bypass_failed.txt
‚îî‚îÄ‚îÄ final/
    ‚îú‚îÄ‚îÄ accessible_domains.csv
    ‚îî‚îÄ‚îÄ full_report.json

scripts/
‚îú‚îÄ‚îÄ 01_dns_check.py
‚îú‚îÄ‚îÄ 02_http_probe.py
‚îú‚îÄ‚îÄ 03_cloudflare_bypass.py
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ chunker.py
‚îÇ   ‚îú‚îÄ‚îÄ resolver.py
‚îÇ   ‚îî‚îÄ‚îÄ reporter.py
‚îî‚îÄ‚îÄ config.yaml

logs/
‚îî‚îÄ‚îÄ *.log
```

---

## Performance Targets

| Stage | Tool | Expected Speed | Time for 6M |
|-------|------|----------------|-------------|
| DNS Check | dnsx | ~50k/min | ~2 hours |
| HTTP Probe | httpx | ~30k/min | ~3-4 hours |
| CF Bypass | curl_cffi | ~5k/min | ~2-3 hours (subset) |

**Total estimated time:** 6-10 hours on a good VPS

---

## Configuration

**config.yaml:**
```yaml
# Threads and concurrency
dns_threads: 300
http_threads: 200
bypass_threads: 100

# Timeouts (seconds)
dns_timeout: 3
http_timeout: 5
bypass_timeout: 15

# Retry settings
max_retries: 3
retry_delay: 1

# Chunk size for processing
chunk_size: 100000

# Output formats
output_json: true
output_csv: true

# Cloudflare detection
cloudflare_indicators:
  - "cloudflare"
  - "cf-ray"
  - "challenge-platform"
```

---

## CLI Commands Reference

### DNS Check with dnsx
```bash
# MX records
cat domains.txt | dnsx -mx -silent -r resolvers.txt -t 300 -o mx_results.txt

# A records
cat domains.txt | dnsx -a -silent -r resolvers.txt -t 300 -resp -o a_results.txt

# Full recon
cat domains.txt | dnsx -recon -json -silent -t 300 -o full_dns.json
```

### DNS Check with massdns (fallback)
```bash
./bin/massdns -r resolvers.txt -t MX -o J domains.txt > mx_results.json
./bin/massdns -r resolvers.txt -t A -o J domains.txt > a_results.json
```

### HTTP Probe with httpx
```bash
cat domains.txt | httpx -silent -t 200 -timeout 5 \
    -status-code -title -tech-detect -cdn -json \
    -o http_results.json
```

### Cloudflare Bypass with curl_cffi
```python
from curl_cffi import requests
r = requests.get("https://example.com", impersonate="chrome", timeout=10)
```

---

## Errors to Avoid

### DNS Stage
- ‚ùå Don't use public resolvers without rate limiting ‚Üí Use resolver rotation
- ‚ùå Don't trust single DNS response ‚Üí Use multiple resolvers for validation
- ‚ùå Don't ignore NXDOMAIN ‚Üí Log them separately for analysis

### HTTP Stage  
- ‚ùå Don't follow infinite redirects ‚Üí Set max_redirects=5
- ‚ùå Don't ignore SSL errors silently ‚Üí Log them with verify=False flag
- ‚ùå Don't hammer single IP ‚Üí Implement per-IP rate limiting

### Cloudflare Bypass
- ‚ùå Don't use FlareSolverr for mass scanning ‚Üí Too slow (2-5s/request)
- ‚ùå Don't expect 100% bypass rate ‚Üí Accept 60-80% is realistic
- ‚ùå Don't run from datacenter IPs ‚Üí Use residential proxies if needed

### General
- ‚ùå Don't load entire file in memory ‚Üí Use generators and streaming
- ‚ùå Don't ignore keyboard interrupts ‚Üí Implement graceful shutdown with state save
- ‚ùå Don't mix languages ‚Üí Keep everything in English

---

## Testing Commands

```bash
# Test DNS setup
echo "google.com" | dnsx -a -silent

# Test HTTP setup
echo "https://google.com" | httpx -silent -status-code

# Test curl_cffi
python -c "from curl_cffi import requests; print(requests.get('https://httpbin.org/ip', impersonate='chrome').json())"

# Test FlareSolverr
curl -X POST http://localhost:8191/v1 -H "Content-Type: application/json" \
    -d '{"cmd":"request.get","url":"https://example.com","maxTimeout":60000}'
```

---

## Monitoring Progress

```bash
# Watch output file growth
watch -n 5 'wc -l output/*.txt'

# Monitor system resources
htop

# Check error logs
tail -f logs/*.log | grep -i error
```

---

## Workflow

- **Branch**: `<type>/<issue-number>-<description>` from `main`
- **Commit**: `<type>: <description>` (English, lowercase, max 72 chars)
- **PR**: Link with `Closes #XX`, squash merge, delete branch
- **Board**: Issues tracked in GitHub Project "claude-apps"
- **Labels**: `/setup-labels` to configure, `type/*` + `size/*` required per issue

---

*This file is part of Claude's prompt. Iterate and refine it as issues are encountered.*
*Press `#` during coding to add instructions automatically.*
